PORT=3001
APP_BASE_URL=http://localhost:3001

# Logging
LOG_LEVEL=info

# AI Model (provider:model format)
# Examples:
#   openai:gpt-4.1-mini
#   openai:gpt-4o
#   anthropic:claude-sonnet-4-20250514
#   google:gemini-2.5-flash
#   bedrock:anthropic.claude-sonnet-4-20250514-v1:0
#   openrouter:openai/gpt-4.1-mini
#   openrouter:anthropic/claude-sonnet-4
AI_MODEL=

# Reasoning tokens (optional, OpenRouter only)
# Set max tokens for reasoning models (e.g., DeepSeek V3.2)
# AI_REASONING_MAX_TOKENS=

# OpenAI
OPENAI_API_KEY=

# Anthropic
ANTHROPIC_API_KEY=

# Google
GOOGLE_GENERATIVE_AI_API_KEY=

# OpenRouter
OPENROUTER_API_KEY=

# Image Storage: local / s3
IMAGE_STORAGE=local

# S3 Storage (required when IMAGE_STORAGE=s3)
S3_BUCKET=
S3_REGION=

# AWS Credentials (for Bedrock and S3)
# Optional if ~/.aws/credentials exists or running on Lambda with IAM Role
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=us-east-1  # Default region for Bedrock (S3 uses S3_REGION)
